{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/tristansones-dykes/scientific-computing/EdwardAlice/Ssd1_CRACanalysis_2020/motif_conservation'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "BIOLIB_TOKEN = \"ohb4uNi529bzwmmmCbA1JgXsOO37kudtGTvAdFy955k\"\n",
    "os.environ[\"BIOLIB_TOKEN\"] = BIOLIB_TOKEN\n",
    "\n",
    "#set directory to /Users/tristansones-dykes/scientific-computing/EdwardAlice/Ssd1_CRACanalysis_2020/motif_conservation\n",
    "os.chdir(\"/Users/tristansones-dykes/scientific-computing/EdwardAlice/Ssd1_CRACanalysis_2020/motif_conservation\")\n",
    "\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-10 15:38:41,976 | INFO : Loaded project DTU/SignalP-6:0.0.56\n",
      "2023-07-10 15:38:42,817 | INFO : Job \"c5f4159a-dae1-4c8f-b3cb-f5348cd9cf7e\" is starting...\n",
      "2023-07-10 15:38:47,904 | INFO : Cloud: Initializing\n",
      "2023-07-10 15:38:50,160 | INFO : Cloud: Downloading Source Files...\n",
      "2023-07-10 15:38:50,160 | INFO : Cloud: Pulling images...\n",
      "2023-07-10 15:38:50,161 | INFO : Cloud: Computing...\n",
      "2023-07-10 15:38:52,404 | INFO : Cloud: Computation finished\n",
      "usage: SignalP 6.0 Signal peptide prediction tool\n",
      "       [-h]\n",
      "       --fastafile\n",
      "       FASTAFILE\n",
      "       --output_dir\n",
      "       OUTPUT_DIR\n",
      "       [--format [{txt,png,eps,all,none}]]\n",
      "       [--organism [{eukarya,other,euk}]]\n",
      "       [--mode [{fast,slow,slow-sequential}]]\n",
      "       [--bsize BSIZE]\n",
      "       [--write_procs WRITE_PROCS]\n",
      "       [--torch_num_threads TORCH_NUM_THREADS]\n",
      "       [--version]\n",
      "       [--skip_resolve]\n",
      "       [--model_dir MODEL_DIR]\n",
      "\n",
      "optional arguments:\n",
      "  -h, --help\n",
      "    show this\n",
      "    help\n",
      "    message and\n",
      "    exit\n",
      "  --fastafile FASTAFILE, -ff FASTAFILE, -fasta FASTAFILE\n",
      "    Amino acid\n",
      "    sequences\n",
      "    to predict\n",
      "    in FASTA\n",
      "    format.\n",
      "    (default:\n",
      "    None)\n",
      "  --output_dir OUTPUT_DIR, -od OUTPUT_DIR\n",
      "    Path at\n",
      "    which to\n",
      "    save the\n",
      "    output\n",
      "    files. Will\n",
      "    be created\n",
      "    if not\n",
      "    existing\n",
      "    already.\n",
      "    (default:\n",
      "    None)\n",
      "  --format [{txt,png,eps,all,none}], -fmt [{txt,png,eps,all,none}], -f [{txt,png,eps,all,none}], -format [{txt,png,eps,all,none}]\n",
      "    Type of\n",
      "    single-\n",
      "    sequence\n",
      "    output\n",
      "    files to be\n",
      "    created.\n",
      "    `txt`\n",
      "    produces\n",
      "    tabular\n",
      "    output,\n",
      "    `png`,\n",
      "    `eps` and\n",
      "    `all` addit\n",
      "    ionally\n",
      "    produce\n",
      "    figures.\n",
      "    `none` only\n",
      "    creates\n",
      "    prediction\n",
      "    summary\n",
      "    files.\n",
      "    (default:\n",
      "    txt)\n",
      "  --organism [{eukarya,other,euk}], -org [{eukarya,other,euk}]\n",
      "    The\n",
      "    organism\n",
      "    group of\n",
      "    origin of\n",
      "    the\n",
      "    sequences.\n",
      "    `eukarya`,\n",
      "    `euk` limit\n",
      "    predictions\n",
      "    to Sec/SPI.\n",
      "    (default:\n",
      "    other)\n",
      "  --mode [{fast,slow,slow-sequential}], -m [{fast,slow,slow-sequential}]\n",
      "    Which\n",
      "    prediction\n",
      "    model to\n",
      "    use. Modes\n",
      "    might have\n",
      "    to be\n",
      "    installed\n",
      "    manually.\n",
      "    (default:\n",
      "    fast)\n",
      "  --bsize BSIZE, -bs BSIZE, -batch BSIZE\n",
      "    Batch size\n",
      "    for\n",
      "    prediction.\n",
      "    Use to\n",
      "    adjust\n",
      "    performance\n",
      "    to your\n",
      "    system\n",
      "    memory.\n",
      "    (default:\n",
      "    10)\n",
      "  --write_procs WRITE_PROCS, -wp WRITE_PROCS\n",
      "    Number of\n",
      "    parallel\n",
      "    processes\n",
      "    used for\n",
      "    writing\n",
      "    ouput\n",
      "    files. Use\n",
      "    to adjust\n",
      "    performance\n",
      "    to your\n",
      "    system\n",
      "    memory.\n",
      "    (default:\n",
      "    8)\n",
      "  --torch_num_threads TORCH_NUM_THREADS, -tt TORCH_NUM_THREADS\n",
      "    Number of\n",
      "    threads\n",
      "    used by\n",
      "    PyTorch for\n",
      "    neural\n",
      "    network\n",
      "    execution.\n",
      "    (default:\n",
      "    8)\n",
      "  --version\n",
      "    show\n",
      "    program's\n",
      "    version\n",
      "    number and\n",
      "    exit\n",
      "  --skip_resolve\n",
      "    Skip\n",
      "    resolving\n",
      "    conflicts\n",
      "    of the\n",
      "    model's\n",
      "    Viterbi\n",
      "    path and\n",
      "    marginal pr\n",
      "    obabilities\n",
      "    . In\n",
      "    general,\n",
      "    should not\n",
      "    be\n",
      "    activated\n",
      "    as it might\n",
      "    cause incon\n",
      "    sistent\n",
      "    prediction\n",
      "    behaviour.\n",
      "    (default:\n",
      "    False)\n",
      "  --model_dir MODEL_DIR, -md MODEL_DIR\n",
      "    Path to\n",
      "    directory\n",
      "    that\n",
      "    contains\n",
      "    the model\n",
      "    files. Use\n",
      "    only when\n",
      "    not\n",
      "    following\n",
      "    default ins\n",
      "    tallation i\n",
      "    nstructions\n",
      "    . (default:\n",
      "    /usr/local/\n",
      "    lib/python3\n",
      "    .8/site-pac\n",
      "    kages/signa\n",
      "    lp/model_we\n",
      "    ights)\n",
      "Traceback (most recent call last):\n",
      "  File \"generate_output.py\", line 4, in <module>\n",
      "    results = json.load(open(\"output/output.json\",\"r\"))\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'output/output.json'\n",
      "2023-07-10 15:38:54,648 | INFO : Cloud: Result Ready\n",
      "usage: SignalP 6.0 Signal peptide prediction tool\n",
      "       [-h]\n",
      "       --fastafile\n",
      "       FASTAFILE\n",
      "       --output_dir\n",
      "       OUTPUT_DIR\n",
      "       [--format [{txt,png,eps,all,none}]]\n",
      "       [--organism [{eukarya,other,euk}]]\n",
      "       [--mode [{fast,slow,slow-sequential}]]\n",
      "       [--bsize BSIZE]\n",
      "       [--write_procs WRITE_PROCS]\n",
      "       [--torch_num_threads TORCH_NUM_THREADS]\n",
      "       [--version]\n",
      "       [--skip_resolve]\n",
      "       [--model_dir MODEL_DIR]\n",
      "\n",
      "optional arguments:\n",
      "  -h, --help\n",
      "    show this\n",
      "    help\n",
      "    message and\n",
      "    exit\n",
      "  --fastafile FASTAFILE, -ff FASTAFILE, -fasta FASTAFILE\n",
      "    Amino acid\n",
      "    sequences\n",
      "    to predict\n",
      "    in FASTA\n",
      "    format.\n",
      "    (default:\n",
      "    None)\n",
      "  --output_dir OUTPUT_DIR, -od OUTPUT_DIR\n",
      "    Path at\n",
      "    which to\n",
      "    save the\n",
      "    output\n",
      "    files. Will\n",
      "    be created\n",
      "    if not\n",
      "    existing\n",
      "    already.\n",
      "    (default:\n",
      "    None)\n",
      "  --format [{txt,png,eps,all,none}], -fmt [{txt,png,eps,all,none}], -f [{txt,png,eps,all,none}], -format [{txt,png,eps,all,none}]\n",
      "    Type of\n",
      "    single-\n",
      "    sequence\n",
      "    output\n",
      "    files to be\n",
      "    created.\n",
      "    `txt`\n",
      "    produces\n",
      "    tabular\n",
      "    output,\n",
      "    `png`,\n",
      "    `eps` and\n",
      "    `all` addit\n",
      "    ionally\n",
      "    produce\n",
      "    figures.\n",
      "    `none` only\n",
      "    creates\n",
      "    prediction\n",
      "    summary\n",
      "    files.\n",
      "    (default:\n",
      "    txt)\n",
      "  --organism [{eukarya,other,euk}], -org [{eukarya,other,euk}]\n",
      "    The\n",
      "    organism\n",
      "    group of\n",
      "    origin of\n",
      "    the\n",
      "    sequences.\n",
      "    `eukarya`,\n",
      "    `euk` limit\n",
      "    predictions\n",
      "    to Sec/SPI.\n",
      "    (default:\n",
      "    other)\n",
      "  --mode [{fast,slow,slow-sequential}], -m [{fast,slow,slow-sequential}]\n",
      "    Which\n",
      "    prediction\n",
      "    model to\n",
      "    use. Modes\n",
      "    might have\n",
      "    to be\n",
      "    installed\n",
      "    manually.\n",
      "    (default:\n",
      "    fast)\n",
      "  --bsize BSIZE, -bs BSIZE, -batch BSIZE\n",
      "    Batch size\n",
      "    for\n",
      "    prediction.\n",
      "    Use to\n",
      "    adjust\n",
      "    performance\n",
      "    to your\n",
      "    system\n",
      "    memory.\n",
      "    (default:\n",
      "    10)\n",
      "  --write_procs WRITE_PROCS, -wp WRITE_PROCS\n",
      "    Number of\n",
      "    parallel\n",
      "    processes\n",
      "    used for\n",
      "    writing\n",
      "    ouput\n",
      "    files. Use\n",
      "    to adjust\n",
      "    performance\n",
      "    to your\n",
      "    system\n",
      "    memory.\n",
      "    (default:\n",
      "    8)\n",
      "  --torch_num_threads TORCH_NUM_THREADS, -tt TORCH_NUM_THREADS\n",
      "    Number of\n",
      "    threads\n",
      "    used by\n",
      "    PyTorch for\n",
      "    neural\n",
      "    network\n",
      "    execution.\n",
      "    (default:\n",
      "    8)\n",
      "  --version\n",
      "    show\n",
      "    program's\n",
      "    version\n",
      "    number and\n",
      "    exit\n",
      "  --skip_resolve\n",
      "    Skip\n",
      "    resolving\n",
      "    conflicts\n",
      "    of the\n",
      "    model's\n",
      "    Viterbi\n",
      "    path and\n",
      "    marginal pr\n",
      "    obabilities\n",
      "    . In\n",
      "    general,\n",
      "    should not\n",
      "    be\n",
      "    activated\n",
      "    as it might\n",
      "    cause incon\n",
      "    sistent\n",
      "    prediction\n",
      "    behaviour.\n",
      "    (default:\n",
      "    False)\n",
      "  --model_dir MODEL_DIR, -md MODEL_DIR\n",
      "    Path to\n",
      "    directory\n",
      "    that\n",
      "    contains\n",
      "    the model\n",
      "    files. Use\n",
      "    only when\n",
      "    not\n",
      "    following\n",
      "    default ins\n",
      "    tallation i\n",
      "    nstructions\n",
      "    . (default:\n",
      "    /usr/local/\n",
      "    lib/python3\n",
      "    .8/site-pac\n",
      "    kages/signa\n",
      "    lp/model_we\n",
      "    ights)\n",
      "Traceback (most recent call last):\n",
      "  File \"generate_output.py\", line 4, in <module>\n",
      "    results = json.load(open(\"output/output.json\",\"r\"))\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'output/output.json'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import biolib\n",
    "\n",
    "signalp_6 = biolib.load(\"DTU/SignalP_6\")\n",
    "job = signalp_6.cli(args='--help')\n",
    "print(job.get_stdout().decode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created file: data/proteins/SignalP/protein_list_1.fasta with 500 proteins\n",
      "Created file: data/proteins/SignalP/protein_list_2.fasta with 500 proteins\n",
      "Created file: data/proteins/SignalP/protein_list_3.fasta with 500 proteins\n",
      "Created file: data/proteins/SignalP/protein_list_4.fasta with 500 proteins\n",
      "Created file: data/proteins/SignalP/protein_list_5.fasta with 500 proteins\n",
      "Created file: data/proteins/SignalP/protein_list_6.fasta with 500 proteins\n",
      "Created file: data/proteins/SignalP/protein_list_7.fasta with 500 proteins\n",
      "Created file: data/proteins/SignalP/protein_list_8.fasta with 500 proteins\n",
      "Created file: data/proteins/SignalP/protein_list_9.fasta with 500 proteins\n",
      "Created file: data/proteins/SignalP/protein_list_10.fasta with 500 proteins\n",
      "Created file: data/proteins/SignalP/protein_list_11.fasta with 500 proteins\n",
      "Created file: data/proteins/SignalP/protein_list_12.fasta with 500 proteins\n",
      "Created file: data/proteins/SignalP/protein_list_13.fasta with 500 proteins\n",
      "Created file: data/proteins/SignalP/protein_list_14.fasta with 500 proteins\n",
      "Created file: data/proteins/SignalP/protein_list_15.fasta with 500 proteins\n",
      "Created file: data/proteins/SignalP/protein_list_16.fasta with 500 proteins\n",
      "Created file: data/proteins/SignalP/protein_list_17.fasta with 500 proteins\n",
      "Created file: data/proteins/SignalP/protein_list_18.fasta with 500 proteins\n",
      "Created file: data/proteins/SignalP/protein_list_19.fasta with 500 proteins\n",
      "Created file: data/proteins/SignalP/protein_list_20.fasta with 500 proteins\n",
      "Created file: data/proteins/SignalP/protein_list_21.fasta with 500 proteins\n",
      "Created file: data/proteins/SignalP/protein_list_22.fasta with 212 proteins\n"
     ]
    }
   ],
   "source": [
    "from Bio import SeqIO\n",
    "\n",
    "def split_fasta_file(input_file, output_prefix, batch_size):\n",
    "    records = list(SeqIO.parse(input_file, \"fasta\"))\n",
    "\n",
    "    # Calculate the number of output files\n",
    "    num_files = len(records) // batch_size\n",
    "    if len(records) % batch_size != 0:\n",
    "        num_files += 1\n",
    "\n",
    "    # Split the records into batches and write to individual files\n",
    "    for i in range(num_files):\n",
    "        start_index = i * batch_size\n",
    "        end_index = (i + 1) * batch_size\n",
    "        batch_records = records[start_index:end_index]\n",
    "        output_file = f\"{output_prefix}_{i+1}.fasta\"\n",
    "        SeqIO.write(batch_records, output_file, \"fasta\")\n",
    "        print(f\"Created file: {output_file} with {len(batch_records)} proteins\")\n",
    "\n",
    "\n",
    "# Usage\n",
    "input_file = \"data/proteins/GenesByTaxon.fasta\"\n",
    "output_prefix = \"data/proteins/SignalP/protein_list\"\n",
    "batch_size = 500\n",
    "split_fasta_file(input_file, output_prefix, batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-10 15:59:21,315 | INFO : Cloud: Initializing\n",
      "2023-07-10 15:59:21,318 | INFO : Cloud: Downloading Source Files...\n",
      "2023-07-10 15:59:21,318 | INFO : Cloud: Pulling images...\n",
      "2023-07-10 15:59:21,319 | INFO : Cloud: Computing...\n",
      "Predicting: 100% 500/500 [06:02<00:00,  1.38sequences/s]\n",
      "Writing files: 100% 500/500 [00:01<00:00, 398.32it/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"generate_output.py\", line 4, in <module>\n",
      "    results = json.load(open(\"output/output.json\",\"r\"))\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'output/output.json'\n",
      "2023-07-10 16:03:46,447 | INFO : Cloud: Computation finished\n",
      "2023-07-10 16:03:46,451 | INFO : Cloud: Result Ready\n",
      "2023-07-10 16:03:46,455 | INFO : Waiting for job 56da0012-c715-4106-8b2f-a54c02010738 to finish...\n",
      "2023-07-10 16:03:49,680 | INFO : Job 56da0012-c715-4106-8b2f-a54c02010738 has finished.\n",
      "2023-07-10 16:03:49,684 | INFO : Waiting for job 04cd7099-1727-4f48-9619-85d6a5a41e69 to finish...\n",
      "2023-07-10 16:06:31,339 | INFO : Job 04cd7099-1727-4f48-9619-85d6a5a41e69 has finished.\n",
      "2023-07-10 16:06:31,349 | INFO : Waiting for job 14c7c6ab-7646-4285-80a3-a46c77ca7db9 to finish...\n",
      "2023-07-10 16:08:26,137 | INFO : Job 14c7c6ab-7646-4285-80a3-a46c77ca7db9 has finished.\n",
      "2023-07-10 16:08:26,148 | INFO : Waiting for job f3c4a55b-342a-4f94-a155-66836df609e6 to finish...\n",
      "2023-07-10 16:08:26,683 | INFO : Job f3c4a55b-342a-4f94-a155-66836df609e6 has finished.\n",
      "2023-07-10 16:08:26,684 | INFO : Waiting for job a0d8ed2b-c6dc-40b3-82cb-cc0a8a123cc5 to finish...\n",
      "2023-07-10 16:08:27,404 | INFO : Job a0d8ed2b-c6dc-40b3-82cb-cc0a8a123cc5 has finished.\n",
      "2023-07-10 16:08:27,406 | INFO : Waiting for job 0035fc78-19f0-43b3-aa24-887ed950d423 to finish...\n",
      "2023-07-10 16:08:28,013 | INFO : Job 0035fc78-19f0-43b3-aa24-887ed950d423 has finished.\n",
      "2023-07-10 16:08:28,014 | INFO : Waiting for job 3f2638dd-2670-43a2-8527-5c7539933e36 to finish...\n",
      "2023-07-10 16:08:34,014 | INFO : Job 3f2638dd-2670-43a2-8527-5c7539933e36 has finished.\n",
      "2023-07-10 16:08:34,015 | INFO : Waiting for job e4139929-c9e4-4571-9026-e964ea16a30b to finish...\n",
      "2023-07-10 16:08:34,545 | INFO : Job e4139929-c9e4-4571-9026-e964ea16a30b has finished.\n",
      "2023-07-10 16:08:34,546 | INFO : Waiting for job e0587719-16ec-4548-a95e-27e441fa5c28 to finish...\n",
      "2023-07-10 16:08:35,082 | INFO : Job e0587719-16ec-4548-a95e-27e441fa5c28 has finished.\n",
      "2023-07-10 16:08:35,083 | INFO : Waiting for job 7d24be5a-3a49-470e-bb7a-e24462f0b2b3 to finish...\n",
      "2023-07-10 16:08:35,682 | INFO : Job 7d24be5a-3a49-470e-bb7a-e24462f0b2b3 has finished.\n",
      "2023-07-10 16:08:35,683 | INFO : Waiting for job b4e8d315-f11d-4f90-8eb5-9636fa81aa1b to finish...\n",
      "2023-07-10 16:08:36,605 | INFO : Job b4e8d315-f11d-4f90-8eb5-9636fa81aa1b has finished.\n",
      "2023-07-10 16:08:36,607 | INFO : Waiting for job 2cd04e41-b1b1-45d8-a258-feefca3c2a4e to finish...\n",
      "2023-07-10 16:08:37,213 | INFO : Job 2cd04e41-b1b1-45d8-a258-feefca3c2a4e has finished.\n",
      "2023-07-10 16:08:37,215 | INFO : Waiting for job 95cc692a-556c-43c9-bdc0-5e8deae0edbb to finish...\n",
      "2023-07-10 16:08:37,887 | INFO : Job 95cc692a-556c-43c9-bdc0-5e8deae0edbb has finished.\n",
      "2023-07-10 16:08:37,889 | INFO : Waiting for job 8d8848eb-ce32-4ee7-8fa0-258052d31644 to finish...\n",
      "2023-07-10 16:08:38,552 | INFO : Job 8d8848eb-ce32-4ee7-8fa0-258052d31644 has finished.\n",
      "2023-07-10 16:08:38,554 | INFO : Waiting for job 72f61105-4d03-41ad-b0ba-01f52aa924d9 to finish...\n",
      "2023-07-10 16:08:39,154 | INFO : Job 72f61105-4d03-41ad-b0ba-01f52aa924d9 has finished.\n",
      "2023-07-10 16:08:39,156 | INFO : Waiting for job ec49c4c4-51f3-4fe3-a61a-74c8b97be231 to finish...\n",
      "2023-07-10 16:08:39,769 | INFO : Job ec49c4c4-51f3-4fe3-a61a-74c8b97be231 has finished.\n",
      "2023-07-10 16:08:39,771 | INFO : Waiting for job e3adc048-8f38-4da4-ba0c-25139de483cd to finish...\n",
      "2023-07-10 16:08:40,499 | INFO : Job e3adc048-8f38-4da4-ba0c-25139de483cd has finished.\n",
      "2023-07-10 16:08:40,501 | INFO : Waiting for job c33cead8-2a0a-49fa-9c79-fbc958edc425 to finish...\n",
      "2023-07-10 16:08:41,158 | INFO : Job c33cead8-2a0a-49fa-9c79-fbc958edc425 has finished.\n",
      "2023-07-10 16:08:41,159 | INFO : Waiting for job 374ec7ad-1408-44c2-b8bd-beca1bb92434 to finish...\n",
      "2023-07-10 16:08:41,828 | INFO : Job 374ec7ad-1408-44c2-b8bd-beca1bb92434 has finished.\n",
      "2023-07-10 16:08:41,830 | INFO : Waiting for job c8d4ddd9-a985-4f77-9f5c-bc0270b4a1e7 to finish...\n",
      "2023-07-10 16:08:42,620 | INFO : Job c8d4ddd9-a985-4f77-9f5c-bc0270b4a1e7 has finished.\n",
      "2023-07-10 16:08:42,622 | INFO : Waiting for job a4515b96-c08c-4922-8120-405f0786a55a to finish...\n",
      "2023-07-10 16:08:43,202 | INFO : Job a4515b96-c08c-4922-8120-405f0786a55a has finished.\n",
      "2023-07-10 16:08:43,204 | INFO : Waiting for job 5f74ff9d-5e9c-411f-8860-3567a6d2efd5 to finish...\n",
      "2023-07-10 16:08:43,873 | INFO : Job 5f74ff9d-5e9c-411f-8860-3567a6d2efd5 has finished.\n",
      "All jobs finished\n"
     ]
    }
   ],
   "source": [
    "# Run SignalP on all the files\n",
    "path, dirs, files = next(os.walk(\"data/proteins/SignalP\"))\n",
    "file_count = len(files)\n",
    "\n",
    "fasta_files = [f\"data/proteins/SignalP/protein_list_{i}.fasta\" for i in range(1, file_count + 1)]\n",
    "my_jobs = []\n",
    "\n",
    "for index, file in enumerate(fasta_files):\n",
    "    job = signalp_6.cli(args = f\"-ff {file} -od data/proteins/results/ --organism euk\", blocking=False, result_prefix=f\"list_{index}\")\n",
    "    my_jobs.append(job)\n",
    "\n",
    "my_jobs[0].stream_logs()\n",
    "\n",
    "for job in my_jobs:\n",
    "    job.wait()\n",
    "\n",
    "print(\"All jobs finished\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
